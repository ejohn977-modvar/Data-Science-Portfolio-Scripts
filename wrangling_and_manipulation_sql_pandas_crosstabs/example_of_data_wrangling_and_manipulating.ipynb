{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pyodbc\r\n",
    "import pandas as pd\r\n",
    "import datetime as dt\r\n",
    "import numpy as np\r\n",
    "from datetime import timedelta\r\n",
    "import csv\r\n",
    "#with open([confidential].csv, 'w', newline='') as f:\r\n",
    "    #writer = csv.writer(f)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#  Outfile location to be determined.\r\n",
    " #outfile = \"[confidential].txt\";\r\n",
    "\r\n",
    "#Code to connect to data warehouse 1. driver = type of server. \r\n",
    "# server = sql server's name \r\n",
    "# database = which database on the sql server you want to access.\r\n",
    "# trusted connection = yes just means you won't have a security error thrown.\r\n",
    "\r\n",
    "connection = pyodbc.connect(driver = '{SQL SERVER}', \r\n",
    "                            Server = '[confidential]',\r\n",
    "                            Database = '[confidential]',\r\n",
    "                            trusted_connection = 'yes')\r\n",
    "\r\n",
    "# Was having trouble without department names to narrow query.\r\n",
    "# Used SAS to creat table below and pulled it in as csv.\r\n",
    "\r\n",
    "crc_orditem_query = \"\"\"\r\n",
    "select OrderHeaderID as ohid, CustomerID as cid, oi.SaleDate as sd, Quantity as quant, NetSalesAmount as nsa, \r\n",
    "DiscountAmount as da, dp.SubCategoryCode as subcat, dp.SubCategoryName as subcatname\r\n",
    "from fact_OrderItem as oi\r\n",
    "inner join dim_Product as dp on oi.ProductID = dp.ProductID\r\n",
    "where dp.subcategorycode in ('02','01','03')\r\n",
    "and dp.DepartmentCode in ('02')\r\n",
    "and dp.CategoryCode = ('04')\r\n",
    "and oi.SaleDate >= '2018-06-28' and oi.SaleDate <= '2019-06-28';\"\"\"\r\n",
    "\r\n",
    "crc_orderitem = pd.read_sql_query(crc_orditem_query, connection)\r\n",
    "print(crc_orderitem.head(100))\r\n",
    "\r\n",
    "\r\n",
    "crc_orderitem['sd'] = pd.to_datetime(crc_orderitem['sd'])\r\n",
    "crc_orderitem['cid'] = crc_orderitem['cid'].fillna(value = -1)\r\n",
    "crc_orderitem['cid'] = crc_orderitem['cid'].astype('int64')\r\n",
    "crc_orderitem['quant'] = crc_orderitem['quant'].astype('int64')\r\n",
    "crc_orderitem['subcat'] = crc_orderitem['subcat'].fillna(value = -1)\r\n",
    "crc_orderitem['subcat'] = crc_orderitem['subcat'].astype('int64')\r\n",
    "\r\n",
    "def convert_currency(val):\r\n",
    "    \"\"\" \\\r\n",
    "    Convert the string number value to a float\r\n",
    "     - Remove $\r\n",
    "     - Remove commas\r\n",
    "     - Convert to float type\r\n",
    "    \"\"\"\r\n",
    "    new_val = val.replace(',','').replace('$', '')\r\n",
    "    return float(new_val)\r\n",
    "\r\n",
    "crc_orderitem['nsa'] = crc_orderitem['nsa'].apply(convert_currency)\r\n",
    "crc_orderitem['da'] = crc_orderitem['da'].apply(convert_currency)\r\n",
    "print(crc_orderitem.dtypes)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dim_date_query = \"\"\"\r\n",
    "select FY_No, FW_No, icDisplayDate as date\r\n",
    "from dim_Date\r\n",
    "where icDisplayDate >= '2018-06-28' and icDisplayDate <= '2019-06-28' \"\"\"\r\n",
    "dim_date = pd.read_sql_query(dim_date_query, connection)\r\n",
    "dim_date['date'] = pd.to_datetime(dim_date['date'])\r\n",
    "\r\n",
    "crc_orders = pd.merge(crc_orderitem, dim_date, how = 'inner', left_on = 'sd', right_on = 'date')\r\n",
    "\r\n",
    "\r\n",
    "crc_orders['cake_accesories_fl'] = np.where(crc_orders['subcat'] == 54, 1, 0)\r\n",
    "crc_orders['cake_machine_fl'] = np.where(crc_orders['subcat'] == 52, 1, 0)\r\n",
    "crc_orders['tools_mats_and_accessories_fl'] = np.where(crc_orders['subcat'] == 2, 1, 0)\r\n",
    "crc_orders['machines_bundles_fl'] = np.where(crc_orders['subcat'] == 1, 1, 0)\r\n",
    "crc_orders['vinyls_and_iron-on_rolls_fl'] = np.where(crc_orders['subcat'] == 3, 1, 0)\r\n",
    "\r\n",
    "#crc_orders.to_csv('[confidential]\\\\crc_orders.csv')\r\n",
    "\r\n",
    "crc_orders.dtypes\r\n",
    "\r\n",
    "def return_inst(series):\r\n",
    "    return series.iloc[0]\r\n",
    "\r\n",
    "# a basic groupby customer id order header id and product subcategory name \r\n",
    "# with dictionary mapping for columns and aggregating functions     \r\n",
    "trans_crc = crc_orders.groupby(['cid','ohid','subcatname']).agg({'quant':'sum', 'nsa':'sum', 'da':'sum', 'tools_mats_and_accessories_fl':'max', 'machines_bundles_fl':'max', 'crc Vinyls & Iron-On Rolls_FL':'max', 'sd':'return_inst', 'FY_No':'return_inst', 'FW_No':'return_inst'})\r\n",
    "\r\n",
    "\r\n",
    "trans_crc = trans_crc.reset_index()\r\n",
    "\r\n",
    "def aur(df):\r\n",
    "    return df['nsa'].sum() / df['quant'].sum()\r\n",
    "\r\n",
    "def metrics(df):\r\n",
    "    s = []\r\n",
    "    trans_ct = df['ohid'].nunique()\r\n",
    "    s.append(trans_ct)\r\n",
    "    quant_sum = df['quant'].sum()\r\n",
    "    s.append(quant_sum)\r\n",
    "    quant_mean = df['quant'].sum() / df['ohid'].nunique()\r\n",
    "    s.append(quant_mean)\r\n",
    "    sales_per_trans = df['nsa'].sum() / df['ohid'].nunique()\r\n",
    "    s.append(sales_per_trans)\r\n",
    "    sales_per_quant = df['nsa'].sum() / quant_sum\r\n",
    "    s.append(sales_per_quant)\r\n",
    "    \r\n",
    "    return pd.Series(s, index = ['Transactions', 'Total Quantity', 'Quantity per Transaction', \\\r\n",
    "                                 'Sales per Transaction', 'Sales per Unit'])\r\n",
    " \r\n",
    "    \r\n",
    "    \r\n",
    "\r\n",
    "trans_FWoI = trans_crc.query('20 <= FW_No <= 26')\r\n",
    "fw_subcat_breakout = trans_FWoI.groupby(['FW_No', 'subcatname']).apply(metrics)\r\n",
    "fw_overall = trans_FWoI.groupby('FW_No').apply(metrics)\r\n",
    "#print(test)\r\n",
    "trans_FWoI = trans_crc.query('20 <= FW_No <= 26')\r\n",
    "AUR = trans_FWoI.groupby(['FW_No', 'subcatname'], as_index = False).apply(aur)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trans_crc['cid'] = trans_crc['cid'].astype('int64')\r\n",
    "print(trans_crc.dtypes)\r\n",
    "\r\n",
    "# a function returns a series of days between visits to sum up those days eventually\r\n",
    "def dbtwv_calc(df):\r\n",
    "    if len(df['sd']) == 1:\r\n",
    "        df.at[:,'sd'] = -1\r\n",
    "        return df['sd']\r\n",
    "    \r\n",
    "    else:\r\n",
    "        df['sd'] = df['sd'].sort_values()\r\n",
    "        diff = df['sd'].diff()\r\n",
    "        diff = diff.dropna()\r\n",
    "        diff = diff.apply(lambda x: x.days)\r\n",
    "        return diff\r\n",
    "\r\n",
    "def ohid_ret(s):\r\n",
    "    return s\r\n",
    "test = trans_crc.loc[trans_crc['cid'] > -1]\r\n",
    "trans_freq = test.groupby(['cid','subcatname','sd'], as_index = False).agg({'ohid':ohid_ret})\r\n",
    "trans_freq.head(10)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#trans_freq = trans_freq.reset_index()\r\n",
    "print(trans_freq.columns)\r\n",
    "test2 = trans_freq.copy()\r\n",
    "trans_freq1 = test2.groupby(['cid','subcatname']).apply(dbtwv_calc)\r\n",
    "trans_freq1 = trans_freq1.reset_index()\r\n",
    "#trans_freq1.to_csv('[confidential]\\\\test.csv')\r\n",
    "trans_freq2 = pd.DataFrame(trans_freq1)\r\n",
    "trans_freq2 = trans_freq2.drop('level_2', axis = 1)\r\n",
    "trans_freq2 = trans_freq2[trans_freq2.sd != -1]\r\n",
    "trans_freq2.query('sd == 0.0')\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dbtwv_lab = [\"{0} - {1}\".format(days, days + 14) for days in range(15, 226, 15)]\r\n",
    "dbtwv_b = [x - 1 for x in range(0,226,15)]\r\n",
    "dbtwv_b.append(370)\r\n",
    "dbtwv_b.insert(1,6)\r\n",
    "dbtwv_b.insert(1,2)\r\n",
    "dbtwv_lab.append('225+')\r\n",
    "dbtwv_lab[0] = '0-2'\r\n",
    "dbtwv_lab.insert(1,'7-14')\r\n",
    "dbtwv_lab.insert(1,'3-6')\r\n",
    "print(trans_freq1.agg({'sd':'max'}))\r\n",
    "\r\n",
    "trans_freq2['dbtwv_bins'] = pd.cut(x = trans_freq2['sd'], bins = dbtwv_b, labels = dbtwv_lab)\r\n",
    "trans_freq2.to_excel('[confidential]\\\\dbtwv.xlsx')\r\n",
    "\r\n",
    "piv_bysubcat = pd.pivot_table(trans_freq2, index = 'dbtwv_bins', columns = 'subcatname', \\\r\n",
    "                      values = 'sd', aggfunc = 'count', dropna = False)\r\n",
    "\r\n",
    "\r\n",
    "piv_bysubcatpct = piv_bysubcat.copy()\r\n",
    "for x in piv_bysubcatpct.columns.to_list():\r\n",
    "    piv_bysubcatpct[x] = piv_bysubcatpct[x] / piv_bysubcatpct[x].sum()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "piv_ov = pd.pivot_table(trans_freq2, index = 'dbtwv_bins', \\\r\n",
    "                      values = 'sd', \\\r\n",
    "                         aggfunc = 'count', dropna = False)\r\n",
    "\r\n",
    "piv_ovpct = piv_ov.copy()\r\n",
    "\r\n",
    "for x in piv_ov.columns.to_list():\r\n",
    "    piv_ovpct[x] = piv_ovpct[x] / piv_ovpct[x].sum()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "def stats(df):\r\n",
    "    count = df['sd'].count()\r\n",
    "    mean = df['sd'].mean()\r\n",
    "    median = df['sd'].median()\r\n",
    "    stats = [count, mean, median]\r\n",
    "    s = pd.Series(stats)\r\n",
    "    return s\r\n",
    "\r\n",
    "stat_bysubcat = trans_freq2.groupby('subcatname', as_index = False).apply(stats)\r\n",
    "stat_bysubcat = stat_bysubcat.T\r\n",
    "stat_bysubcat = stat_bysubcat.reset_index()\r\n",
    "stats_ov = trans_freq2.agg({'sd':['count', 'mean', 'median']})\r\n",
    "stats_ov = stats_ov.reset_index()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "trans_out = piv_ov.join(piv_bysubcat)\r\n",
    "trans_outpct = piv_ovpct.join(piv_bysubcatpct)\r\n",
    "\r\n",
    "print(trans_out)\r\n",
    "trans_outpct.to_excel('[confidential]\\\\dbtwv_dist.xlsx')\r\n",
    "stats = pd.merge(stats_ov, stat_bysubcat, left_index = True, right_index = True)\r\n",
    "stats = stats.reset_index()\r\n",
    "stats.to_csv('[confidential]\\\\dbtwv_stats.csv')\r\n",
    "\r\n",
    "print(\"Done!\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# making some pivot tables for visualizing sales and transaction\r\n",
    "# distributions by category and subcategory\r\n",
    "trans_crc2 = crc_orders.groupby(['cid','ohid'], as_index = False).agg('tools_mats_and_accessories_fl':'max', 'machines_bundles_fl':'max', 'vinyls_and_iron-on_rolls_fl':'max'})\r\n",
    "\r\n",
    "\r\n",
    "trans_crc3 = trans_crc2.groupby('cid', as_index = False).agg({'tools_mats_and_accessories_fl':'sum', \\\r\n",
    "                                                  'machines_bundles_fl':'sum', \\\r\n",
    "                                       'vinyls_and_iron-on_rolls_fl':'sum'})\r\n",
    "\r\n",
    "trans_crc_cidpres = trans_crc3[trans_crc3['cid'] != -1]\r\n",
    "\r\n",
    "trans_crc_cidpres1 = trans_crc2[trans_crc2['cid'] != -1]\r\n",
    "\r\n",
    "#print(trans_crc_cidpres)\r\n",
    "\r\n",
    "bin_lab = [\"{0}\".format(trans) for trans in range(1, 10, 1)]\r\n",
    "transb = list([x for x in range(0,10,1)])\r\n",
    "bin_lab.append('10+')\r\n",
    "transb.append(52)\r\n",
    "\r\n",
    "\r\n",
    "trans_tool1 = trans_crc_cidpres.loc[trans_crc_cidpres['tools_mats_and_accessories_fl'] > 0]\r\n",
    "trans_mach1 = trans_crc_cidpres.loc[trans_crc_cidpres['machines_bundles_fl'] > 0]\r\n",
    "trans_vinyl1 = trans_crc_cidpres.loc[trans_crc_cidpres['vinyls_and_iron-on_rolls_fl'] > 0]\r\n",
    "\r\n",
    "trans_tool = trans_tool1.loc[:,['cid', 'tools_mats_and_accessories_fl']]\r\n",
    "trans_mach = trans_mach1.loc[:,['cid','machines_bundles_fl']]\r\n",
    "trans_vinyl = trans_vinyl1.loc[:,['cid', 'vinyls_and_iron-on_rolls_fl']]\r\n",
    "\r\n",
    "\r\n",
    "trans_tool['Transactions'] = pd.cut(x = trans_tool['tools_mats_and_accessories_fl'], \\\r\n",
    "                                  bins = transb, labels = bin_lab)\r\n",
    "trans_mach['Transactions'] = pd.cut(x = trans_mach['machines_bundles_fl'], \\\r\n",
    "                                  bins = transb, labels = bin_lab)\r\n",
    "trans_vinyl['Transactions'] = pd.cut(x = trans_vinyl['vinyls_and_iron-on_rolls_fl'], \\\r\n",
    "                                  bins = transb, labels = bin_lab)\r\n",
    "\r\n",
    "#print(trans_tool.head(), trans_vinyl.head(10), trans_mach.head(10))\r\n",
    "\r\n",
    "piv_tool = pd.pivot_table(trans_tool, index = 'Transactions', \\\r\n",
    "                      values = 'tools_mats_and_accessories_fl', \\\r\n",
    "                          aggfunc = 'count', dropna = False)\r\n",
    "tool_stats = trans_tool.agg({'tools_mats_and_accessories_fl':['count','mean','median']})\r\n",
    "\r\n",
    "piv_mach = pd.pivot_table(trans_mach, index = 'Transactions', \\\r\n",
    "                      values = 'machines_bundles_fl', \\\r\n",
    "                          aggfunc = 'count', dropna = False)\r\n",
    "\r\n",
    "mach_stats = trans_mach.agg({'machines_bundles_fl':['count','mean','median']})\r\n",
    "\r\n",
    "piv_vinyl = pd.pivot_table(trans_vinyl, index = 'Transactions', \\\r\n",
    "                      values = 'vinyls_and_iron-on_rolls_fl', \\\r\n",
    "                          aggfunc = 'count', dropna = False)\r\n",
    "vinyl_stats = trans_vinyl.agg({'vinyls_and_iron-on_rolls_fl':['count','mean','median']})\r\n",
    "\r\n",
    "trans_bysubcat = piv_tool.join([piv_mach, piv_vinyl])\r\n",
    "\r\n",
    "def tot_trans(df):\r\n",
    "    tool = df['tools_mats_and_accessories_fl'].sum()\r\n",
    "    mach = df['machines_bundles_fl'].sum()\r\n",
    "    vinyl = df['vinyls_and_iron-on_rolls_fl'].sum()\r\n",
    "    tot  = tool + mach + vinyl\r\n",
    "    return tot\r\n",
    "\r\n",
    "trans_ov = trans_crc_cidpres1.groupby('cid').agg({'ohid':'nunique'})\r\n",
    "trans_ov = trans_ov.reset_index()\r\n",
    "#trans_ov = trans_ov.rename({'cid':'cid', 0:'trans'}, axis = 1)\r\n",
    "trans_ov['Transactions'] = pd.cut(x = trans_ov['ohid'], \\\r\n",
    "                                  bins = transb, labels = bin_lab)\r\n",
    "piv_ov = pd.pivot_table(trans_ov, index = 'Transactions', \\\r\n",
    "                      values = 'ohid', \\\r\n",
    "                          aggfunc = 'count', dropna = False)\r\n",
    "\r\n",
    "ov_stats = trans_ov.agg({'ohid':['count','mean','median']})\r\n",
    "\r\n",
    "trans_out = piv_ov.join(trans_bysubcat)\r\n",
    "trans_outpct = trans_out.copy()\r\n",
    "\r\n",
    "\r\n",
    "for x in trans_outpct.columns.to_list():\r\n",
    "    trans_outpct[x] = trans_outpct[x] / trans_outpct[x].sum()\r\n",
    "    \r\n",
    "\r\n",
    "trans_stats_out = ov_stats.join([tool_stats,mach_stats,vinyl_stats])\r\n",
    "    \r\n",
    "    \r\n",
    "print(trans_out, trans_stats_out)\r\n",
    "\r\n",
    "trans_out.to_excel('[confidential]_trans_dist.xlsx')\r\n",
    "trans_outpct.to_excel('[confidential]_trans_distpct.xlsx')\r\n",
    "trans_stats_out.to_csv('[confidential]_trans_stats.csv')\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [
    "t"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}